{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeb4f852",
   "metadata": {},
   "source": [
    "# Understand and use peformance log files in TRUST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925ded6c",
   "metadata": {},
   "source": [
    "## TRUST counters\n",
    "\n",
    "In order to obtain statistics on the performance of a test case, **TRUST** uses counters. Counters are C++ objects. \n",
    "\n",
    "Their main purpose is to serve as **time watches** for parts of the code you deem important. They also track additional metrics:\n",
    "\n",
    "**Timing statistics:**\n",
    "- Minimum, maximum, average and standard deviation of the measured time per time step\n",
    "\n",
    "**Usage metrics:**\n",
    "- An integer called `count` tracking the number of times the counter has been started and stopped\n",
    "- A custom integer called `quantity`, mainly used to measure the quantity of bytes exchanged during communication operations, or to store the number of iterations of the linear solver\n",
    "\n",
    "**Identification:**\n",
    "- `std::string` attributes `description` and `family`. A description is mandatory for each counter. The family attribute is by default set to `\"None\"` but can be used as a key for regrouping the counters you want to parse together after your computation.\n",
    "\n",
    "**Level management:**\n",
    "Counters also have a certain level. The level of a counter is represented by an integer. It makes sure that you know when you open your counter. Indeed, if a counter of level 1 is running, you can only start a counter of level 2. Otherwise, the code will stop. In the same logic, you can only close the most recently opened counter. Because of this interlock structure, counters also have another interesting metric called **alone_time**. It is the elapsed time where the considered counter is the last opened one (i.e., excluding time spent in nested counters). This metric is printed in the CSV output file and helps identify the intrinsic cost of each code section.\n",
    "\n",
    "**Example of the level hierarchy:**\n",
    "```cpp\n",
    "statistics().begin_count(STD_COUNTERS::total_execution_time, -1);           // Level -1 - reserved to the total execution time counter\n",
    "    statistics().begin_count(STD_COUNTERS::timeloop, 0);                    // Level 0  - reserved to counters of the global steps\n",
    "        statistics().begin_count(STD_COUNTERS::convection, 1);              // Level 1  - only possible while Level 0 is running\n",
    "            statistics().begin_count(STD_COUNTERS::mpi_recv, 2);            // Level 2  - only possible while Level 1 is running\n",
    "            statistics().end_count(STD_COUNTERS::mpi_recv, 1 , nb_exchanged_bytes);\n",
    "        statistics().end_count(STD_COUNTERS::convection);\n",
    "    statistics().end_count(STD_COUNTERS::timeloop);\n",
    "statistics().end_count(STD_COUNTERS::total_execution_time);\n",
    "```\n",
    "This ensures proper nesting and helps track where time is spent in your code hierarchy.\n",
    "\n",
    "Those counter objects are managed by the Perf_counters class. In practice, you will only need to interact with the Perf_counters class (not with individual counter objects directly). The Perf_counters class follows a singleton pattern and a Pimpl pattern, such that the implementation of the class is hidden in the Perf_counters.cpp file. The unique instance of Perf_counters can be called inside the code by using:\n",
    "\n",
    "```cpp\n",
    "statistics()\n",
    "```\n",
    "\n",
    "The unique instance of Perf_counters will be created at the first `statistics()` call.  \n",
    "\n",
    "The counters managed by the Perf_counters instance are separated in two types:\n",
    "- the standard counters used by default in **TRUST** and identified by a `STD_COUNTERS` key (`STD_COUNTERS` is an enum class),\n",
    "- custom counters that can be created inside the code and that are identified by a `std::string`. \n",
    "\n",
    "The basic API for counters in **TRUST** is as follows:\n",
    "\n",
    "```cpp\n",
    "#include <Perf_counters.h>\n",
    "\n",
    "statistics().begin_count(MY_COUNTER_KEY, level);\n",
    "{\n",
    "    // The block of code I want to have statistics about\n",
    "    std::cout << \"Time elapsed since the counter has last been opened:\" << statistics().get_time_since_last_open(MY_COUNTER_KEY)<< std::endl;\n",
    "}\n",
    "statistics().end_count(MY_COUNTER_KEY, count, quantity);\n",
    "```\n",
    "\n",
    "MY_COUNTER_KEY is either a `STD_COUNTERS` if you want to open a standard **TRUST** counter or the `std::string` that corresponds to the description of the custom counter you try to open. In the `statistics().begin_count()` function, the `level` parameter is optional. If omitted, the counter will automatically use the one defined at the creation of the counter. If you are having trouble determining the level of your counter, you can use the function `statistics().get_last_opened_counter_level()` to know the level of the last opened counter. The `count` parameter specifies how much to increment the counter's total count (i.e., how many times to record this begin/end cycle). It is set by default to 1. The `quantity` parameter specifies how much to increment the quantity attribute of your counter and is by default set to 0.\n",
    "\n",
    "\n",
    "During a **TRUST** computation, **TRUST** statistics are measured through 3 main steps: \n",
    "- Computation start-up \n",
    "- Time loop\n",
    "- Post-resolution\n",
    "\n",
    "At the end of each step, the counters are reset and statistics are printed in the two files:\n",
    "- `MY_TRUST_CASE_NAME.TU` \n",
    "- `MY_TRUST_CASE_NAME_csv.TU`\n",
    "\n",
    "The first file contains aggregated stats that are the most commonly used alongside some information regarding the environment of your computation (date, OS, CPU model, GPU model if you run a GPU computation, number of CPU processors used, ...). It has been designed to be human readable, but it is not easy to parse it informatically.\n",
    "The second file has been created for easily parsing each and every counter's data with your favorite csv parsing tool, for example [pandas](https://pandas.pydata.org/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efee8c22-906b-43ce-9450-4d452e19421c",
   "metadata": {},
   "source": [
    "## Standard TRUST counters\n",
    "Here is the list of the standard **TRUST** counters:\n",
    "\n",
    "| Key | Description | Family | Is_communication | Is_gpu |\n",
    "|-----|-------------|--------|------------------|--------|\n",
    "| total_execution_time | Total time | None | False | False |\n",
    "| computation_start_up | Computation start-up | None | False | False |\n",
    "| timeloop | Time loop | None | False | False |\n",
    "| backup_file | Back-up operations | None | False | False |\n",
    "| system_solver | Linear solver resolutions Ax=B | None | False | False |\n",
    "| petsc_solver | Petsc solver | None | False | False |\n",
    "| implicit_diffusion | Solver for implicit diffusion | None | False | False |\n",
    "| compute_dt | Computation of the time step dt | None | False | False |\n",
    "| turbulent_viscosity | Turbulence model::update | None | False | False |\n",
    "| convection | Convection operator | None | False | False |\n",
    "| diffusion | Diffusion operator | None | False | False |\n",
    "| gradient | Gradient operator | None | False | False |\n",
    "| divergence | Divergence operator | None | False | False |\n",
    "| rhs | Source terms | None | False | False |\n",
    "| postreatment | Post-treatment operations | None | False | False |\n",
    "| restart | Read file for restart | None | False | False |\n",
    "| matrix_assembly | Nb matrix assembly for implicit scheme: | None | False | False |\n",
    "| update_variables | Update ::mettre_a_jour | None | False | False |\n",
    "| mpi_sendrecv | MPI_send_recv | MPI_sendrecv | true | False |\n",
    "| mpi_send | MPI_send | MPI_sendrecv | true | False |\n",
    "| mpi_recv | MPI_recv | MPI_sendrecv | true | False |\n",
    "| mpi_bcast | MPI_broadcast | MPI_sendrecv | true | False |\n",
    "| mpi_alltoall | MPI_alltoall | MPI_sendrecv | true | False |\n",
    "| mpi_allgather | MPI_allgather | MPI_sendrecv | true | False |\n",
    "| mpi_gather | MPI_gather | MPI_sendrecv | true | False |\n",
    "| mpi_partialsum | MPI_partialsum | MPI_allreduce | true | False |\n",
    "| mpi_sumdouble | MPI_sumdouble | MPI_allreduce | true | False |\n",
    "| mpi_mindouble | MPI_mindouble | MPI_allreduce | true | False |\n",
    "| mpi_maxdouble | MPI_maxdouble | MPI_allreduce | true | False |\n",
    "| mpi_sumfloat | MPI_sumfloat | MPI_allreduce | true | False |\n",
    "| mpi_minfloat | MPI_minfloat | MPI_allreduce | true | False |\n",
    "| mpi_maxfloat | MPI_maxfloat | MPI_allreduce | true | False |\n",
    "| mpi_sumint | MPI_sumint | MPI_allreduce | true | False |\n",
    "| mpi_minint | MPI_minint | MPI_allreduce | true | False |\n",
    "| mpi_maxint | MPI_maxint | MPI_allreduce | true | False |\n",
    "| mpi_barrier | MPI_barrier | MPI_allreduce | true | False |\n",
    "| gpu_library | GPU_library | GPU_library | false | true |\n",
    "| gpu_kernel | GPU_kernel | GPU_kernel | false | true |\n",
    "| gpu_copytodevice | GPU_copyToDevice | GPU_copy | false | true |\n",
    "| gpu_copyfromdevice | GPU_copyFromDevice | GPU_copy | false | true |\n",
    "| gpu_malloc_free | GPU_allocations | GPU_alloc | false | true |\n",
    "| interprete_scatter | Scatter_interprete | None | true | false |\n",
    "| virtual_swap | DoubleVect/IntVect::virtual_swap | None | true | False |\n",
    "| read_scatter | Scatter::read_domaine | None | true | False |\n",
    "| parallel_meshing | Parallel meshing | None | False | False |\n",
    "| IO_EcrireFicPartageBin | write | IO | False | False |\n",
    "| IO_EcrireFicPartageMPIIO | MPI_File_write_all | IO | False | False |\n",
    "   \n",
    "\n",
    "You can use them whenever you need to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45601380-4feb-4636-b71b-31c3e306e3f8",
   "metadata": {},
   "source": [
    "### Custom TRUST counters\n",
    "\n",
    "As explained above, on top of standard counters, you can also create and use custom counters. To create a new custom counter, you just need to add the following in your code:\n",
    "```cpp\n",
    "statistics().create_custom_counter(std::string counter_description, int counter_level,  std::string counter_family = \"None\", bool is_comm=false, bool is_gpu=false);\n",
    "```\n",
    "Then, you can open and close your new counter, using `std::string counter_description` as your new counter key. All of the custom counters will be printed in both TU files.\n",
    "\n",
    "\n",
    "Warning: if a custom counter already has your `std::string counter_description`, the function `statistics().create_custom_counter()` will not create another counter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1836874",
   "metadata": {},
   "source": [
    "### Description of the csv file\n",
    " \n",
    "The performance log file CASE_NAME_csv.TU stores the statistics in a table for each counter on a specific test case. This table has the following columns: \n",
    "\n",
    "\"Overall_simulation_step\", \"Processor_Number\", \"Counter_family\", \"Counter_name\",  \"Counter_level\", \"Is_comm\", \"%_total_time\", \"total time\", \"t_min\", \"t_max\", \"t_SD\", \"time_alone\", \"t_alone_min\", \"t_alone_max\", \"t_alone_SD\",  \"count\", \"time_per_step\", \"tps_min\", \"tps_max\", \"tps_SD\", \"Quantity\", \"q_min\", \"q_max\", \"q_SD\"\n",
    "\n",
    "Column delimiter is a tabulation. The first four columns create a unique key for a row.\n",
    "\n",
    "\"Overall_simulation_step\" stands respectively for the three main steps of the calculation. \n",
    "\n",
    "Column Is_comm enable to know if the counter is a communication counter or not. If it is equal to 1, then it is a communication counter. Otherwise, it is not.\n",
    "\n",
    "\"%_total_time\" gives the percentage of time used by a peculiar counter with respect to the total time used for the main step of calculation (initialisation, resolution and post processing).\n",
    "\n",
    "By default, averaged statistics on all processors are also available under Processor_Number == -1. For accessing the detail per processor, add **stat_per_proc_perf_log 1** in the data file. Moreover, if count is equal to zero, then the counter was not called during the computation.\n",
    "\n",
    "SD stands for standard deviation. Min and max denote the minimum and maximum value over every processor of the accounted quantity. The \"time_per_step\" column stores the average time elapsed in a time step on the tracked operation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3cc734",
   "metadata": {},
   "source": [
    "## Exemple on the simple test case Obstacle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a8856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustutils import run\n",
    "\n",
    "run.TRUST_parameters(\"1.9.7_beta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7045f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.reset()\n",
    "case1 = run.addCase(\".\",\"Obstacle.data\",nbProcs=2)\n",
    "case1.partition()\n",
    "run.printCases()\n",
    "run.runCases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731a5cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.tablePerf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58571774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(run.BUILD_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405de649",
   "metadata": {},
   "source": [
    "First, we need to know the number of rows of comments there are before the table starts. Those rows always start with the character #."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a14bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_file = open('PAR_Obstacle_csv.TU',\"r\") \n",
    "\n",
    "lines=perf_file.readlines()\n",
    "\n",
    "nb_comment_lines=0\n",
    "\n",
    "while (lines[nb_comment_lines][0]=='#'):\n",
    "    nb_comment_lines +=1\n",
    "\n",
    "print(nb_comment_lines)  \n",
    "\n",
    "perf_file.closed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbe01f1",
   "metadata": {},
   "source": [
    "The file contains some white spaces, in order to make it readable by a human. They have to be removed so as to have a clean MultiIndex. To do so, three functions are created : strip, make_int and make_float. \n",
    "\n",
    "The column names are specified in the variable col_names. Here, by default, the same name as the first row of the table has been used, but you can customize it.\n",
    "\n",
    "Then, the file is open using pandas library and converted into a DataFrame. A quick user guide for pandas library can be found at : https://pandas.pydata.org/docs/user_guide/10min.html\n",
    "\n",
    "For opening the file, the function read.csv is used. The first argument is the path to the .csv file. Then, by using sep='\\t' we specify that the delimiter of the table is a tabulation. Header = 0 enables to change properly the name of the colums from the first row to the ones contain in the variable col_names. Argument index_col specifies the number of columns used as a key for a row (this will create a MultiIndex). Converters are used to discard useless white spaces in the table.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b31e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as math\n",
    "import re as re\n",
    "\n",
    "def strip(text):\n",
    "    try:\n",
    "        return text.strip()\n",
    "    except AttributeError:\n",
    "        return text\n",
    "\n",
    "def make_int(text):\n",
    "    return int(text.strip('\" '))\n",
    "\n",
    "def make_float(text):\n",
    "    return float(text.strip('\" '))\n",
    "\n",
    "col_names=[\"Overall_simulation_step\", \"Processor_Number\", \"Counter_family\", \"Counter_name\",  \"Counter_level\", \"Is_comm\", \"%_total_time\", \"total_time\", \"t_min\", \"t_max\", \"t_SD\", \"time alone\", \"t_alone_min\", \"t_alone_max\", \"t_alone_SD\", \"count\", \"time_per_step\", \"tps_min\", \"tps_max\", \"tps_SD\", \"Quantity\", \"q_min\", \"q_max\", \"q_SD\"]\n",
    "\n",
    "M=pd.read_csv('PAR_Obstacle_csv.TU', keep_default_na=False , sep='\\t', skiprows = nb_comment_lines, header=0, names=col_names, index_col=(0,1,2,3), converters= {\"Overall_simulation_step\" : strip, \"Processor_Number\" : make_int, \"Counter_family\" : strip, \"Counter_name\" : strip, \"Counter_level\" : make_int, \"Is_comm\" : make_int, \"%_total_time\" : make_float, \"total time\" : make_float, \"t_min\" : make_float, \"t_max\" : make_float, \"t_SD\" : make_float, \"count\" : make_float, \"c_min\" : make_float, \"c_max\" : make_float, \"c_SD\" : make_float, \"time_per_step\" : make_float, \"tps_min\" : make_float, \"tps_max\" : make_float, \"tps_SD\" : make_float, \"Quantity\" : make_float, \"q_min\" : make_float, \"q_max\" : make_float, \"q_SD\" : make_float  })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76ce525",
   "metadata": {},
   "source": [
    "If you have a doubt in the MultiIndex, you can print it by using :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a0573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = M.index\n",
    "\n",
    "print(M.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a777d9",
   "metadata": {},
   "source": [
    "You can also have generic infromation about the DataFrame by using :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcefe16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "M.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6695fcb4",
   "metadata": {},
   "source": [
    "An advantage of the MultiIndex is that it is quite easy to make selection on partial index. First, let's create three sub DataFrames, one for each overall simulation step :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e30e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_init = M.loc[(\"Computation start-up statistics\")]\n",
    "M_reso = M.loc[(\"Time loop statistics\")]\n",
    "M_post = M.loc[(\"Post-resolution statistics\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5226bf6",
   "metadata": {},
   "source": [
    "## How to reconstruct the agregated data of the .TU file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c3ad70",
   "metadata": {},
   "source": [
    "In the .Tu file, some usefull aggregated values are already computed. In the sequel, we show how to reconstruct them easily from the .csv file. First, let's print the file CASE_NAME.TU :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cc8236",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PAR_Obstacle.TU', 'r') as f:\n",
    "    for lines in f:\n",
    "        print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89922d2",
   "metadata": {},
   "source": [
    "First, we need to know the number of proc used for the simulation. If statistics detailed by processor are printed, you can obtain it with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048d345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nb_proc = np.max( idx.get_level_values(1) ) + 1    \n",
    "print('Nb proc =', Nb_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709a7c95",
   "metadata": {},
   "source": [
    "Else, the information is also given in the second commented line of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827c1596",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nb_proc=0\n",
    "with open('PAR_Obstacle_csv.TU', 'r') as f:\n",
    "    for lines in f:\n",
    "        if lines.startswith('# Number of processor used ='):\n",
    "            Nb_proc = int(re.search(r'= (\\d+)', lines).group(1))\n",
    "            break\n",
    "print('Nb proc =', Nb_proc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e2c9ac",
   "metadata": {},
   "source": [
    "In the sequel, we give an example for treating statistics of the resolution step. Just change the name of the matrix to change of overall step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87cd311",
   "metadata": {},
   "source": [
    "First, let's acces at the total time of the associated overall step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4d9399",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = np.asarray(M_reso.loc[[(-1,\"None\",\"Total time\")],[\"total_time\"]])[0][0]\n",
    "print(\"Total time of the resolution (time loop) =\",total_time, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546ab1c9",
   "metadata": {},
   "source": [
    "The number of time steps is simply the count of the counter \"Time loop\". One can acces it by using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e8b453",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps=np.asarray(M_reso.loc[[(-1,\"None\",\"Time loop\")],[\"count\"]])[0][0]\n",
    "print('Number of time steps =', timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b367272",
   "metadata": {},
   "source": [
    "Under some conditions, such as a strictly positive number of time steps, most of the aggregated quantities of the CASE_NAME.TU file can be retrieved as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdf6eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "solveur_Axb = np.asarray(M_reso.loc[[(-1,\"None\",\"Linear solver resolutions Ax=B\")],[\"Quantity\"]])[0][0]/timesteps\n",
    "print('Average number of solveur iterations per time step',solveur_Axb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443f7686",
   "metadata": {},
   "outputs": [],
   "source": [
    "solveur_diffusion_implicite = np.asarray(M_reso.loc[[(-1,\"None\",\"Solver for implicit diffusion\")],[\"tps_max\"]])[0][0]\n",
    "print('Maximum time taken for solving the diffusion part per time step = ',solveur_diffusion_implicite ,\"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147be758",
   "metadata": {},
   "outputs": [],
   "source": [
    "assemblage_matrice_implicite = np.asarray(M_reso.loc[[(-1,\"None\",\"Matrix assembly for implicit scheme:\")],[\"tps_max\"]])[0][0]\n",
    "print('Maximum time taken for creating the matrix per time step, when using implicit solver = ',assemblage_matrice_implicite,\"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8282a853",
   "metadata": {},
   "outputs": [],
   "source": [
    "mettre_a_jour = np.asarray(M_reso.loc[[(-1,\"None\",\"Update ::mettre_a_jour\")],[\"tps_max\"]])[0][0]\n",
    "print('Maximum time taken for updating the matrix per time step = ', mettre_a_jour, \"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdac3669",
   "metadata": {},
   "outputs": [],
   "source": [
    "operateurs_convection = np.asarray(M_reso.loc[[(-1,\"None\",\"Convection operator\")],[\"tps_max\"]])[0][0]\n",
    "print('Maximum time per time step for computing the operator of convection =',operateurs_convection,'s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb0c659",
   "metadata": {},
   "outputs": [],
   "source": [
    "operateurs_diffusion =  np.asarray(M_reso.loc[[(-1,\"None\",\"Diffusion operator\")],[\"tps_max\"]])[0][0]\n",
    "print('Maximum time per time step for computing the operator of convection =',operateurs_diffusion,'s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80354c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "operateurs_gradient = np.asarray(M_reso.loc[[(-1,\"None\",\"Gradient operator\")],[\"tps_max\"]])[0][0]\n",
    "print('Maximum time per time step for computing the gradient =',operateurs_gradient,'s')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb78ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "operateurs_divergence =  np.asarray(M_reso.loc[[(-1,\"None\",\"Divergence operator\")],[\"tps_max\"]])[0][0]\n",
    "print('Maximum time per time step for computing the operator divergence =',operateurs_divergence,'s')         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa6e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "operateurs_source = np.asarray(M_reso.loc[[(-1,\"None\",\"Source terms\")],[\"tps_max\"]])[0][0]\n",
    "print('Maximum time per time step for computing source terms =',operateurs_source,'s')          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0946d445",
   "metadata": {},
   "outputs": [],
   "source": [
    "operations_post_traitement =  np.asarray(M_reso.loc[[(-1,\"None\",\"Post-treatment operations\")],[\"tps_max\"]])[0][0]\n",
    "print('Maximum time per time step for post treatment operations =',operations_post_traitement,'s')          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8698b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "calcul_dt = np.asarray(M_reso.loc[[(-1,\"None\",\"Computation of the time step dt\")],[\"tps_max\"]])[0][0]\n",
    "print('Maximum time per time step for computing the time step =',calcul_dt,'s')          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4513237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modele_turbulence = np.asarray(M_reso.loc[[(-1,\"None\",\"Turbulence model::update\")],[\"tps_max\"]])[0][0]\n",
    "print('Maximum time per time step for trating the turbulence =',modele_turbulence,'s')          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c64010",
   "metadata": {},
   "outputs": [],
   "source": [
    "operations_sauvegarde = np.asarray(M_reso.loc[[(-1,\"None\",\"Back-up operations\")],[\"tps_max\"]])[0][0]\n",
    "print('Maximum time per time step for printing back-up =',operations_sauvegarde,'s')          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b499b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "calcul_divers = np.asarray(M_reso.loc[[(-1,\"None\",\"Time loop\")],[\"time alone\"]])[0][0]/timesteps\n",
    "calcul_divers += np.asarray(M_reso.loc[[(-1,\"None\",\"Total time\")],[\"time alone\"]])[0][0]/timesteps\n",
    "print('Averaged time per time step of untracked time =',calcul_divers,'s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc36d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nb_echange_espace_virtuel_per_ts = np.asarray(M_reso.loc[[(-1,\"None\",\"DoubleVect/IntVect::virtual_swap\")],[\"count\"]])[0][0]/timesteps\n",
    "print(\"Average number of virtual swap (echange_espace_virtuel) per time step: \",Nb_echange_espace_virtuel_per_ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312ffd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nb_MPI_allreduce_per_ts = (M_reso.xs('MPI_allreduce', level='Counter_family')['count'].sum())/timesteps \n",
    "print('Average number of MPI_allreduce per time step',Nb_MPI_allreduce_per_ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52965c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nb_solveur_per_ts = np.asarray(M_reso.loc[[(-1,\"None\",\"Linear solver resolutions Ax=B\")],[\"count\"]])[0][0]/timesteps\n",
    "print('Average number of solver called per time step =',Nb_solveur_per_ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d4c731",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (np.asarray(M_reso.loc[[(-1,\"None\",\"Linear solver resolutions Ax=B\")],[\"count\"]])[0][0] > 0 ):\n",
    "    Secondes_per_solveur = np.asarray(M_reso.loc[[(-1,\"None\",\"Linear solver resolutions Ax=B\")],[\"tps_max\"]])[0][0] \n",
    "    Iterations_per_solveur = np.asarray(M_reso.loc[[(-1,\"None\",\"Linear solver resolutions Ax=B\")],[\"q_max\"]])[0][0]/np.asarray(M_reso.loc[[(-1,\"None\",\"Linear solver resolutions Ax=B\")],[\"count\"]])[0][0]\n",
    "    print('Maximum time per step used for solving the inversion problem =',Secondes_per_solveur)\n",
    "    print('Maximum iteration number for solving the inversion problem = ',Iterations_per_solveur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2319ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (np.asarray(M_reso.loc[[(-1,\"None\",\"Back-up operations\")],[\"count\"]])[0][0]>0):\n",
    "    Nb_sauvegardes = np.asarray(M_reso.loc[[(-1,\"None\",\"Back-up operations\")],[\"count\"]])\n",
    "    Data_per_sauvegarde = (Nb_proc*np.asarray(M_reso.loc[[(-1,\"None\",\"Back-up operations\")],[\"Quantity\"]]))[0][0]/(np.asarray(M_reso.loc[[(-1,\"None\",\"Back-up operations\")],[\"count\"]])[0][0] * 1024 *1024)\n",
    "    print('Maximum number of back-up created :', Nb_sauvegardes)\n",
    "    print('Average bytes stored per back-up :', Data_per_sauvegarde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6938aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (np.asarray(M_reso.loc[[(-1,\"GPU_copy\",\"GPU_copyToDevice\")],[\"count\"]])>0):\n",
    "    GPU_libraries = np.asarray(M_reso.loc[[(-1,\"GPU_library\",\"GPU_library\")],[\"count\"]])[0][0]/np.asarray(M_reso.loc[[(-1,\"GPU_library\",\"GPU_library\")],[\"t_max\"]])[0][0]/1024/1024/1024\n",
    "    GPU_kernel = np.asarray(M_reso.loc[[(-1,\"GPU_kernel\",\"GPU_kernel\")],[\"count\"]])[0][0]/np.asarray(M_reso.loc[[(-1,\"GPU_kernel\",\"GPU_kernel\")],[\"t_max\"]])[0][0]/1024/1024/1024\n",
    "    Copy_H2D = np.asarray(M_reso.loc[[(-1,\"GPU_copy\",\"GPU_copyToDevice\")],[\"count\"]])[0][0]\n",
    "    print(GPU_libraries)\n",
    "    print(GPU_kernel)\n",
    "    print(Copy_H2D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61c9ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (M_reso.loc[(-1, \"IO\", \"write\"), \"total_time\"] >0):\n",
    "    Debit_write_seq = Nb_proc*M_reso.loc[(-1, \"IO\", \"write\"), \"Quantity\"]/M_reso.loc[(-1, \"IO\", \"write\"), \"total_time\"]/1024/1024\n",
    "    print('Sequential writing output :',Debit_write_seq, 'Mo/s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f01786",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (M_reso.loc[(-1,\"IO\",\"MPI_File_write_all\"),\"total_time\"] >0):\n",
    "    Debit_write_par = Nb_proc*M_reso.loc[(-1,\"IO\",\"MPI_File_write_all\"),\"Quantity\"]/M_reso.loc[(-1,\"IO\",\"MPI_File_write_all\"),\"total time\"]/1024/1024\n",
    "    print('Parallel writing output :',Debit_write_par, 'Mo/s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ec1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (M_reso[M_reso['Is_comm'] == 1]['count'].sum()> 0):\n",
    "    Communications_avg = M_reso[M_reso['Is_comm'] == 1]['total_time'].sum()/ M_reso.loc[(-1,\"None\",\"Total time\"),\"total_time\"]\n",
    "    Communications_max = M_reso[M_reso['Is_comm'] == 1]['t_max'].sum()/ M_reso.loc[(-1,\"None\",\"Total time\"),\"t_min\"]\n",
    "    Communications_min = M_reso[M_reso['Is_comm'] == 1]['t_min'].sum()/ M_reso.loc[(-1,\"None\",\"Total time\"),\"t_max\"]\n",
    "    print('Average percent of time of communications = ',Communications_avg)\n",
    "    print('Minimum percent of time of communications = ',Communications_min)\n",
    "    print('Maximum percent of time of communications = ',Communications_max)\n",
    "    if (M_reso.loc[(-1,\"MPI_sendrecv\", \"MPI_send_recv\"),\"total_time\"] > 0):\n",
    "        max_bandwidth = 1.0e-6 * (M_reso.loc[(-1,\"MPI_sendrecv\", \"MPI_send_recv\"),\"Quantity\"])/M_reso.loc[(-1,\"MPI_sendrecv\", \"MPI_send_recv\"),\"t_min\"]\n",
    "        print('Evaluation of the maximum badnwidth = ',max_bandwidth, ' MB/s')\n",
    "    Nb_MPI_senrecv_per_ts = (M_reso.xs('MPI_sendrecv', level='Counter_family')['count'].sum())/timesteps \n",
    "    bytes_MPI_senrecv_per_ts = (M_reso.xs('MPI_sendrecv', level='Counter_family')['Quantity'].sum())/timesteps \n",
    "    Total_network_traffic = Nb_proc * 1.0e-6 * bytes_MPI_senrecv_per_ts / timesteps\n",
    "    if(Nb_MPI_senrecv_per_ts>0):\n",
    "        Average_message_size = bytes_MPI_senrecv_per_ts / Nb_MPI_senrecv_per_ts\n",
    "    print('Average total size of send messages per time step = ',Total_network_traffic, ' B per time step')\n",
    "    print('Average size of send messages per exchange = ',Average_message_size, ' MB/s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba8323-4539-4dbb-b6d0-7cb0784ea2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
